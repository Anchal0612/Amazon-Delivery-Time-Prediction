# -*- coding: utf-8 -*-
"""Amazon Delivery Time Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HSmdiiA7gjOg9a5DLDC4QbvgpexxKSb8
"""

# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Ignore warnings
import warnings
warnings.filterwarnings('ignore')

# Step 2: Load Dataset
df = pd.read_csv("amazon_delivery.csv")

# Step 3: Basic Info
print("Shape of dataset:", df.shape)
print("\nFirst 5 rows:\n", df.head())
print("\nData types:\n", df.dtypes)

# Check missing values
print("Missing values in dataset:\n", df.isnull().sum())

# Check duplicates
print("Duplicate rows:", df.duplicated().sum())

df = df.drop_duplicates()

# Convert Order_Date to datetime
df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')

# Convert Order_Time and Pickup_Time to datetime (time only)
df['Order_Time'] = pd.to_datetime(df['Order_Time'], errors='coerce').dt.time
df['Pickup_Time'] = pd.to_datetime(df['Pickup_Time'], errors='coerce').dt.time

print("\nDataset Info after cleaning:")
print(df.info())
print("\nSummary Statistics:\n", df.describe(include='all'))

#Feature Engineering
# Function for haversine distance (in km)
from math import radians, cos, sin, asin, sqrt

def haversine(lon1, lat1, lon2, lat2):
    # convert decimal degrees to radians
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])

    # haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    r = 6371 # Radius of earth in km
    return c * r

# Apply to dataset
df['Distance_km'] = df.apply(lambda x: haversine(x['Store_Longitude'], x['Store_Latitude'],
                                                 x['Drop_Longitude'], x['Drop_Latitude']), axis=1)

print(df[['Store_Latitude','Store_Longitude','Drop_Latitude','Drop_Longitude','Distance_km']].head())

# Fill Agent_Rating with mean
df['Agent_Rating'].fillna(df['Agent_Rating'].mean(), inplace=True)

# Fill categorical columns with mode
df['Order_Time'].fillna(df['Order_Time'].mode()[0], inplace=True)
df['Weather'].fillna(df['Weather'].mode()[0], inplace=True)

# Check missing values
print("Missing values in dataset:\n", df.isnull().sum())

#EDA (Exploratory Data Analysis)
plt.figure(figsize=(8,5))
sns.histplot(df['Delivery_Time'], bins=30, kde=True)
plt.title("Distribution of Delivery Time (hours)")
plt.xlabel("Delivery Time (hours)")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x='Distance_km', y='Delivery_Time', data=df, alpha=0.3)
plt.title("Distance vs Delivery Time")
plt.xlabel("Distance (km)")
plt.ylabel("Delivery Time (hours)")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='Weather', y='Delivery_Time', data=df)
plt.title("Weather vs Delivery Time")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='Traffic', y='Delivery_Time', data=df)
plt.title("Traffic vs Delivery Time")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x='Agent_Rating', y='Delivery_Time', data=df, alpha=0.3)
plt.title("Agent Rating vs Delivery Time")
plt.show()

# Re-convert Order_Time column
df['Order_Time'] = pd.to_datetime(df['Order_Time'], format='%H:%M:%S', errors='coerce')

# Extract hour safely
df['Order_Hour'] = df['Order_Time'].dt.hour

print(df[['Order_Time','Order_Hour']].head())

plt.figure(figsize=(10,6))
sns.heatmap(df[['Agent_Age','Agent_Rating','Distance_km','Order_Hour','Delivery_Time']].corr(),
            annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

#Model Development
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Encode categorical features
cat_cols = ['Weather', 'Traffic', 'Vehicle', 'Area', 'Category']
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

# Features & Target
X = df[['Agent_Age','Agent_Rating','Distance_km','Order_Hour',
        'Weather','Traffic','Vehicle','Area','Category']]
y = df['Delivery_Time']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Train shape:", X_train.shape, " Test shape:", X_test.shape)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Train model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predictions
y_pred = lr.predict(X_test)

# Evaluation
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("Linear Regression Results:")
print("MAE:", mae)
print("RMSE:", rmse)
print("R² Score:", r2)

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("Random Forest Results:")
print("MAE:", mean_absolute_error(y_test, y_pred_rf))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))
print("R² Score:", r2_score(y_test, y_pred_rf))

from sklearn.ensemble import GradientBoostingRegressor

gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=42)
gb.fit(X_train, y_train)

y_pred_gb = gb.predict(X_test)

print("Gradient Boosting Results:")
print("MAE:", mean_absolute_error(y_test, y_pred_gb))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_gb)))
print("R² Score:", r2_score(y_test, y_pred_gb))

import pickle
with open("rf_model.pkl", "wb") as f:
    pickle.dump(rf, f)